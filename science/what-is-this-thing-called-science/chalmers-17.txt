
Chapter 17. Postscript.

In this postscript, Chalmers puts the contents of the book in perspective and
concludes with what seems to be his overall understanding of how science can be
rational and progressive.

[Overview]

My understanding of the model of science he sketches in this chapter can be
summarized as follows:

- A scientific theory may be sketchy [my word] or fully worked out. 

- Because a sketchy theory is high-level and lacks details and precision, it is
  not possible to put it to stringent tests.

- When a sketchy theory is fleshed out with details about the machanisms that
  supposedly lead to the phenomena in question, those detailed mechanisms
  generally yield a variety of phenomena in addition to the original subjects of
  the theory, and hence allow the theory to be put to the test by experiments
  on the full range of its implications.

- Given a body of experimenmtal results relating to a theory, certain
  assumptions of the theory may be strongly confirmed, and other assumptions
  of the theory may not be confirmed at all. 

- It is generally the case that parts that are well-confirmed remain valid
  as limiting cases of superceding theories, while the parts that are not 
  confirmed are eliminated or completely superceded.

- We should therefore stick with theories that are fully fledged, and in 
  addition, try to separate out the parts of each theory that have not been 
  well-confirmed by experiments so far.

- Then in general superceding theories become progressive in the sense that 
  sperceded theories remain valid as special cases of superceding theories, 
  and in that sense science becomes a progresive enterprise.

At least this my take-away from this postscript. Your mileage may vary. And I am
not sure I have fully captured Chalmers' intent by the above summary.

In what follows I will describe some of the above ideas in more detail as 
presented in this chapter.

[Some Specifics]

Realism becomes problematic because theories can be superceded beyond their
observed limits, and the picture of the world provided by the more general 
theory may be radically different from that provided by the earlier thoery.

However, there are elements of theories that it would be silly to think of as
unreal. We can say that they are practically reall as far as we know. Chalmers
considers the electron as practically real.

But the distinction still seems rather subjecive. 

For me, practically real is just good enough. The ontology provided by a
well-confirmed theory is just practically real. We don't have to worry 
about whether it is actually real. Just like we don't have to worry about
whether a scientific fact is absolutely true. 

So rather than speaking of reality and truth which will get us into trouble,
we can just speak of well-confirmed models of the world.

This reduces the issue to the still ultimately subjecive issue of what 
constitutes a well-confirmed theory.

If we think of a well-confirmed theory as basically an abstraction or
factorization of regular observations spanning the entire range of the
applicability of the theory, then it is almost by definition the case that the
theory is correct. The problem is that we cannot possibly observe experimentally
the entire range of applicability of most interseting theories. 

However, assuming that our observations are close enough to areas where
we claim the theory applies to but have not been directly observed, 
it would be quite a coincidence if the theory is not an approximation 
to the situation in the entire range of claimed applicability.

Chalmers considers this type of argument as valid only if the evidence is very
strong and he has a number of criteria for the strength of the evidence.

1. Stringent objective tests.

2. The complete theory has to be stated up front and tests evaluated 
   against that complete theory. If you keep finding anomalies and keep 
   tinkering with the theory (e.g., as in Ptolemy's epicycles) then that 
   is a theory "smell". This is the idea of "accommodation" of a theory 
   to experimental evidence that has not in my mind been precisely defined.

3. Possibilities of error.

   One thing is that a theory may contain multiple sub-theories, 
   and we may not have specific evidence for the specific sub-theories,
   and in fact they could be wrong.
   
   An example is Newton's particle theory of light which conjectured 
   assumptions about the attraction of light by materials, etc. which 
   were just conjectures - not independently tested.
   
   Another issue is that to test a theory one may have to make assumptions
   about the domain of tests, and those assumptions may be wrong.

   An example is the assumption about the distance of the stars in testing
   for parallax that seemingly falsified Copernicus. In this case, the distance 
   assumptions were false.

4. Complete tests of all parts of a theory. The tests purported to confirm a
   theory may only confirm a subset of the postulates of the theory. So care must
   be taken to partition a theory into orthogonal postulates, and claim only those
   potulates that are actually needed to explain the existing observations made in
   experiments so far. An example given is that Newton's theory postulates 
   absolute space, but experiments only deal with the relative positions 
   of the bodies involved and not with absolute space per se.

5. Variety of phenomena explained by a theory. The wider the range of seemingly
   distict  phenomena and discoveries confirming a theory, the stronger is
   the case for the theory. For example, Newton's theory explains planeray orbits,
   billiard balls, tides, etc. It would be an amazing coincidence if the theory were
   just plain wrong.

Chalmers considers the fact that historically accepted theories were rejected 
outright, e.g., Aristotelian theories, as insufficient evidence for the
rejection of currently accepted theories. Some of those theories were 
not confirmed by evidence, I guess, using even the standards of evidence 
of the day. 

But in any case, we now have much better standards of evidence which reduce the
chance of the fallibility of currently accepted theories. 

I guess our standards of rationality and evidence can be improved by future
generations, and by those standards, those future generations can critique
the acceptance by us of certain theories. But we can only use the best standards
of rationality at our disposal at a given time. That is the best we can do
in approximating reality.

Other past theories were well-confirmed by our current standards, and in those
cases they remain valid as limiting cases of the theories that superceded them.

The difference between philosophical and scientific theories. As exemplified by 
the atomic theory of matter.

Ancienet philosophers attempting to explain the nature of change were able to
explain change as a rearrangement of constituent particles. But this was an
explanation of how change CAN happen. They did not show in any direct manner
that this is the way change DOES happen. 

Similarly the atomists of the 17'th century (Newton and Boyle) could show that
an assumption of the atomic nature of matter CAN be used to explain certain
natural phenomena. But according to Chalmers, they too did not produce strong
evidence for the actual atomic nature of matter. I am wondering about the
details of the arguments by Newton and Boyle and how they differed from the
notions of strong evidence listed by Chalmers. 

In any case, when Chalmers talks about "accommodating" a theory to an
experimental observation, what I think he has in mind is that the ontology and
machanisms proposed by the theory CAN be used to explain the observation. But
that strong evidence has not been offered for the claim that that ontologgy and
set of mechanisms actually [closely] describes the underlying reality.

However, for me personally, the fact that the theory can be used to explain 
observed phenomema is a sort of evidence for the theory. So why is it
considered weak as evidence?

It seems that once you flesh out the explanations to an actual theory with the
details worked out, then that completed theory could imply various other
observed phenomena that could be put to the test. And evidence for those
phenomena can only be tested after the ontology and mechanisms of the theory are 
completely specified. In order to flesh out the theory it is often necessary
to augment the original high-level explanatory framework of the theory with
additional assumptions. Which assumptions would have to be strongly confirmed
by experiments for the whole theory to be confirmed.

Chalmers' claim is that strong evidence for the particulate nature of matter was
first provided by J.J. Thompson's cathode ray experiments. One idea of strong
confirmation is that different and unrelated experiments can point to the same
theory. Experiments by Peter Zeeman had also pointed to the existence of charged
particles, additionally confirming the existence of material particles. 

At this time, I don't understand the details of these two experiments to be able
to independently judge their qualitative distinction from the more speculative
theories of earlier scientists. I would have to take Chalmers' word for it for
now. To be further understood.

In any case, the way I see a qualitative distinction (and I am not sure if it
captures the gist of Chalmers's arguments) is this. A speculative [aka
accommodating] theory is one which: 

1. Either is not really a scientific theory because it has not worked out the
details of the ontology and the mechanisms involved in its explanations. This
is clearly the case for the ancient atomic theories. Change can possibly be
explained by a particulate theory, but no details are given as to how it
actually occurs.

2. Or it has speculated on the details, but those details have not been
subjected to serious experimental tests.

Note that by this definition of mine the Ptolemian theory of the planets is 
not really a speculative theory just because it includes epicycles.

An interesting and extreme example of falsification of a theory with supposedly
strong evidence is the explanation of Brownian motion by the kinetic theory of
molecules at the time. In the 1900's Jean Perrin conducted a series of very
careful experiments for observing the behavior of Brownian motion particles. The
results of these experiments perfectly fit the kinetic theory of molecules.
Unfortunately, it turned out later that the theory as known at the time of
Perrin included false postulates concerning the equilibrium of different types
of motions of a particle accounting for its kinetic energy.

The takeaway is that Perrin was mainly concerned with Brownian motion. But the
underlying kinetic theory had various unrelated consequences that only later 
were found not to exist.

In the case of Brownian motion, specific assumptions in the then kinetic theory
of molecules that were used to explain Brownian motion by Perrin were simply
wrong.

A different issue arises when the specific assumptions of a theory are in fact
not needed to explain a phenomenon. The example given by Chalmers is Dalton's
atomic theory of matter. Chalmers proposes that the existence of atoms as basic
constituents of matter was not needed to account for most (all?) of 19'th
century chemistry. 

For example, chemical formulae can be taken to mean quantities of different
constituents of a compound independently of whether the constituents are
particulate. In other words, atomicity is a separable part of 19'th century
chemistry. And the contention is that that part of the theory was not put to
stringent tests in the 19'th century, and the results of 19'th century
experiments could be adequately explained by using only the idea of quantities
of materials participating in chemical reactions.



